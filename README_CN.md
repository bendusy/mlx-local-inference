<p align="center">
  <h1 align="center">ğŸ§  MLX æœ¬åœ°æ¨ç†å…¨å®¶æ¡¶</h1>
  <p align="center">
    åœ¨ Apple Silicon Mac ä¸Šè¿è¡Œå®Œæ•´æœ¬åœ° AI æ¨ç† â€” LLM Â· è¯­éŸ³è¯†åˆ« Â· å‘é‡åŒ– Â· OCR Â· è¯­éŸ³åˆæˆ Â· è‡ªåŠ¨è½¬å½•
  </p>
  <p align="center">
    <a href="https://clawhub.ai/skills/mlx-local-inference"><img src="https://img.shields.io/badge/ClawHub-mlx--local--inference-FF5A36?style=flat-square" alt="ClawHub"></a>
    <a href="#"><img src="https://img.shields.io/badge/å¹³å°-macOS%20Apple%20Silicon-000?style=flat-square&logo=apple&logoColor=white" alt="Platform"></a>
    <a href="#"><img src="https://img.shields.io/badge/è¿è¡Œæ—¶-MLX-blue?style=flat-square" alt="MLX"></a>
    <a href="LICENSE"><img src="https://img.shields.io/badge/è®¸å¯è¯-MIT-green?style=flat-square" alt="License"></a>
  </p>
  <p align="center">
    <a href="README.md">English</a> Â· <b>ä¸­æ–‡</b>
  </p>
</p>

---

ä¸€ä¸ª [OpenClaw](https://github.com/openclaw/openclaw) æŠ€èƒ½åŒ…ï¼Œé€šè¿‡ [MLX](https://github.com/ml-explore/mlx) åœ¨ Apple Silicon Mac ä¸Šæä¾›å®Œæ•´çš„æœ¬åœ° AI æ¨ç†èƒ½åŠ›ã€‚ä¸ä¾èµ–äº‘ç«¯ã€ä¸äº§ç”Ÿ API è´¹ç”¨ã€æ•°æ®å®Œå…¨æœ¬åœ°åŒ–ã€‚

## åŠŸèƒ½æ¦‚è§ˆ

| èƒ½åŠ› | æ¨¡å‹ | ç«¯å£ | è¯´æ˜ |
|:-----|:-----|:-----|:-----|
| **LLM å¯¹è¯** | Qwen3-14B, Gemma3-12B | 8787 | æµå¼è¾“å‡ºã€æ€ç»´é“¾æ¨ç† |
| **è¯­éŸ³è¯†åˆ«** | Qwen3-ASR, Whisper-v3-turbo | 8788 / 8787 | ç²¤è¯­/æ™®é€šè¯å¼ºé¡¹ + 99 ç§è¯­è¨€ |
| **æ–‡æœ¬å‘é‡åŒ–** | Qwen3-Embedding 0.6B / 4B | 8787 | RAGã€è¯­ä¹‰æœç´¢ã€æ–‡æ¡£ç´¢å¼• |
| **OCR** | PaddleOCR-VL-1.5 | CLI | ä¸­è‹±æ–‡åœºæ™¯æ–‡å­—ã€ç¥¨æ®ã€æ–‡æ¡£ |
| **è¯­éŸ³åˆæˆ** | Qwen3-TTS-1.7B | 8788 / CLI | æ”¯æŒè‡ªå®šä¹‰éŸ³è‰²å…‹éš† |
| **è‡ªåŠ¨è½¬å½•** | ASR + LLM è”åˆ | å®ˆæŠ¤è¿›ç¨‹ | æ–‡ä»¶ç›‘å¬ã€è‡ªåŠ¨è½¬å½• + æ™ºèƒ½çº é”™ |

æ‰€æœ‰æœåŠ¡å‡æä¾› **OpenAI å…¼å®¹ API**ï¼Œå¯ç›´æ¥ä½¿ç”¨ `openai` Python SDKã€`curl` æˆ–ä»»ä½•å…¼å®¹å®¢æˆ·ç«¯è°ƒç”¨ã€‚

## ç¯å¢ƒè¦æ±‚

- **ç¡¬ä»¶**ï¼šApple Silicon Macï¼ˆM1 / M2 / M3 / M4ï¼‰
- **ç³»ç»Ÿ**ï¼šmacOS 14+
- **å†…å­˜**ï¼šæ¨è 32GB+ï¼ˆå¤šæ¨¡å‹åŒæ—¶è¿è¡Œï¼‰
- **Python**ï¼š3.10+

## å®‰è£…

### ä½œä¸º OpenClaw Skill å®‰è£…

```bash
clawhub install mlx-local-inference
```

### ç‹¬ç«‹å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/bendusy/mlx-local-inference.git
cd mlx-local-inference

# å®‰è£… Python ä¾èµ–
pip install mlx mlx-lm mlx-audio mlx-vlm openai
```

### ä¸‹è½½æ¨¡å‹

æ¨¡å‹åœ¨é¦–æ¬¡è°ƒç”¨æ—¶è‡ªåŠ¨ä¸‹è½½ï¼Œä¹Ÿå¯ä»¥é¢„å…ˆæ‹‰å–ï¼š

```bash
# LLM
huggingface-cli download Qwen/Qwen3-14B-MLX-4bit
huggingface-cli download mlx-community/gemma-3-text-12b-it-4bit

# è¯­éŸ³è¯†åˆ«
huggingface-cli download mlx-community/Qwen3-ASR-1.7B-8bit
huggingface-cli download mlx-community/whisper-large-v3-turbo

# å‘é‡åŒ–
huggingface-cli download mlx-community/Qwen3-Embedding-0.6B-4bit-DWQ

# OCR
huggingface-cli download mlx-community/PaddleOCR-VL-1.5-6bit

# è¯­éŸ³åˆæˆï¼ˆå¯é€‰ï¼‰
huggingface-cli download mlx-community/Qwen3-TTS-12Hz-1.7B-CustomVoice-8bit
```

## ä½¿ç”¨ç¤ºä¾‹

### LLM å¯¹è¯

```bash
curl http://localhost:8787/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3-14b",
    "messages": [{"role": "user", "content": "ç”¨ä¸€å¥è¯è§£é‡Šé‡å­è®¡ç®—"}]
  }'
```

<details>
<summary>Python ç¤ºä¾‹</summary>

```python
from openai import OpenAI

client = OpenAI(base_url="http://localhost:8787/v1", api_key="unused")
response = client.chat.completions.create(
    model="qwen3-14b",
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    temperature=0.7,
    max_tokens=2048,
)
print(response.choices[0].message.content)
```

</details>

> **æç¤ºï¼š** Qwen3 ä¼šè¾“å‡º `<think>...</think>` æ€ç»´é“¾æ ‡ç­¾ï¼ŒæŒ‰éœ€è¿‡æ»¤ï¼š
> ```python
> import re
> text = re.sub(r'<think>.*?</think>\s*', '', text, flags=re.DOTALL)
> ```

### è¯­éŸ³è¯†åˆ«

```bash
# Qwen3-ASR â€” ç²¤è¯­/æ™®é€šè¯é¦–é€‰
curl http://localhost:8788/v1/audio/transcriptions \
  -F file=@audio.wav \
  -F model=mlx-community/Qwen3-ASR-1.7B-8bit \
  -F language=zh

# Whisper â€” å¤šè¯­è¨€ï¼ˆ99 ç§ï¼‰
curl http://localhost:8787/v1/audio/transcriptions \
  -F file=@audio.wav \
  -F model=whisper-large-v3-turbo
```

æ”¯æŒæ ¼å¼ï¼š`wav`ã€`mp3`ã€`m4a`ã€`flac`ã€`ogg`ã€`webm`

é•¿éŸ³é¢‘å»ºè®®å…ˆåˆ‡åˆ†ä¸º 10 åˆ†é’Ÿç‰‡æ®µï¼š

```bash
ffmpeg -y -ss 0 -t 600 -i long.wav -ar 16000 -ac 1 chunk_000.wav
```

### æ–‡æœ¬å‘é‡åŒ–

```bash
# å•æ¡
curl http://localhost:8787/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen3-embedding-0.6b", "input": "è¦å‘é‡åŒ–çš„æ–‡æœ¬"}'

# æ‰¹é‡
curl http://localhost:8787/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen3-embedding-4b", "input": ["æ–‡æœ¬ä¸€", "æ–‡æœ¬äºŒ"]}'
```

### OCR æ–‡å­—è¯†åˆ«

```bash
python -m mlx_vlm.generate \
  --model mlx-community/PaddleOCR-VL-1.5-6bit \
  --image photo.jpg \
  --prompt "OCR:" \
  --max-tokens 512 \
  --temp 0.0
```

> Prompt å¿…é¡»ä¸º `OCR:`ï¼Œtemperature è®¾ 0 ç¡®ä¿ç¡®å®šæ€§è¾“å‡ºã€‚

### è¯­éŸ³åˆæˆ

```bash
curl http://localhost:8788/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{"model":"mlx-community/Qwen3-TTS-12Hz-1.7B-CustomVoice-8bit","input":"ä½ å¥½ä¸–ç•Œ"}' \
  -o speech.wav
```

### è‡ªåŠ¨è½¬å½•å®ˆæŠ¤è¿›ç¨‹

å°†éŸ³é¢‘æ–‡ä»¶æ”¾å…¥ `~/transcribe/` ç›®å½•ï¼Œå®ˆæŠ¤è¿›ç¨‹è‡ªåŠ¨å¤„ç†ï¼š

1. **Qwen3-ASR è½¬å½•** â†’ `æ–‡ä»¶å_raw.md`
2. **Qwen3-14B æ™ºèƒ½æ ¡å¯¹** â†’ `æ–‡ä»¶å_corrected.md`
3. **å½’æ¡£** â†’ `~/transcribe/done/`

æ ¡å¯¹è§„åˆ™ï¼šåŒéŸ³å­—çº é”™ã€ä¿ç•™ç²¤è¯­ç”¨å­—ï¼ˆå˜…/å””/å’/å–º/å†‡/ä½¢ï¼‰ã€è¡¥å…¨æ ‡ç‚¹ã€å»é™¤è¯­æ°”è¯å’Œé‡å¤ã€‚

## æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Apple Silicon Mac (MLX)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    ç«¯å£ 8787      â”‚       ç«¯å£ 8788            â”‚
â”‚    (å±€åŸŸç½‘å¯è®¿é—®)  â”‚       (ä»…æœ¬æœº)             â”‚
â”‚                  â”‚                           â”‚
â”‚  Â· Qwen3-14B    â”‚  Â· Qwen3-ASR              â”‚
â”‚  Â· Gemma3-12B   â”‚  Â· Qwen3-TTS              â”‚
â”‚  Â· Whisper      â”‚                           â”‚
â”‚  Â· Embedding    â”‚                           â”‚
â”‚    0.6B / 4B    â”‚                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OCR: PaddleOCR-VL           (CLI, æŒ‰éœ€è°ƒç”¨)  â”‚
â”‚  è½¬å½•å®ˆæŠ¤è¿›ç¨‹          (æ–‡ä»¶ç›‘å¬, ASRâ†’LLM æ ¡å¯¹) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## æ¨¡å‹é€‰å‹

### LLM

| åœºæ™¯ | æ¨è |
|:-----|:-----|
| ä¸­æ–‡ / ç²¤è¯­ | `qwen3-14b` |
| è‹±æ–‡ / ä»£ç  | `gemma-3-12b` |
| æ·±åº¦æ¨ç† | `qwen3-14b`ï¼ˆthink æ¨¡å¼ï¼‰ |
| å¿«é€Ÿé—®ç­” | `gemma-3-12b` |

### è¯­éŸ³è¯†åˆ«

| åœºæ™¯ | æ¨è |
|:-----|:-----|
| ç²¤è¯­ / æ™®é€šè¯ | Qwen3-ASR |
| å¤šè¯­è¨€ï¼ˆ99 ç§ï¼‰ | Whisper |

### å‘é‡åŒ–

| åœºæ™¯ | æ¨è |
|:-----|:-----|
| å¿«é€Ÿæ£€ç´¢ / ä½å»¶è¿Ÿ | `qwen3-embedding-0.6b` |
| é«˜ç²¾åº¦è¯­ä¹‰åŒ¹é… | `qwen3-embedding-4b` |

## æœåŠ¡ç®¡ç†

```bash
# ä¸»æœåŠ¡ï¼ˆLLM + Whisper + Embeddingï¼‰
launchctl kickstart -k gui/$(id -u)/com.mlx-server

# ASR + TTS æœåŠ¡
launchctl kickstart -k gui/$(id -u)/com.mlx-audio-server

# è½¬å½•å®ˆæŠ¤è¿›ç¨‹
launchctl kickstart gui/$(id -u)/com.mlx-transcribe-daemon
```

## ç›®å½•ç»“æ„

```
mlx-local-inference/
â”œâ”€â”€ SKILL.md              # OpenClaw æŠ€èƒ½å®šä¹‰
â”œâ”€â”€ README.md             # English
â”œâ”€â”€ README_CN.md          # ä¸­æ–‡è¯´æ˜ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ LICENSE               # MIT
â””â”€â”€ references/           # å„æ¨¡å‹è¯¦ç»†å‚è€ƒæ–‡æ¡£
    â”œâ”€â”€ asr-qwen3.md
    â”œâ”€â”€ asr-whisper.md
    â”œâ”€â”€ embedding-qwen3.md
    â”œâ”€â”€ llm-qwen3-14b.md
    â”œâ”€â”€ llm-gemma3-12b.md
    â”œâ”€â”€ llm-models-reference.md
    â”œâ”€â”€ ocr.md
    â”œâ”€â”€ transcribe-daemon.md
    â””â”€â”€ tts-qwen3.md
```

## è´¡çŒ®

æ¬¢è¿æ Issue å’Œ PRã€‚å„æ¨¡å‹çš„è¯¦ç»†æŠ€æœ¯æ–‡æ¡£è§ `references/` ç›®å½•ã€‚

## è®¸å¯è¯

[MIT](LICENSE)
