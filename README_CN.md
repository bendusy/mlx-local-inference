<p align="center">
  <h1 align="center">ğŸ§  MLX æœ¬åœ°æ¨ç†å…¨å®¶æ¡¶</h1>
  <p align="center">
    è®©ä½ çš„ Apple Silicon Mac å­¦ä¼šå¬ã€çœ‹ã€è¯»ã€è¯´ã€æƒ³ â€” å®Œå…¨æœ¬åœ°åŒ–ã€‚
  </p>
  <p align="center">
    <a href="https://clawhub.ai/skills/mlx-local-inference"><img src="https://img.shields.io/badge/ClawHub-mlx--local--inference-FF5A36?style=flat-square" alt="ClawHub"></a>
    <a href="#"><img src="https://img.shields.io/badge/å¹³å°-macOS%20Apple%20Silicon-000?style=flat-square&logo=apple&logoColor=white" alt="Platform"></a>
    <a href="#"><img src="https://img.shields.io/badge/è¿è¡Œæ—¶-MLX--VLM-blue?style=flat-square" alt="MLX-VLM"></a>
    <a href="LICENSE"><img src="https://img.shields.io/badge/è®¸å¯è¯-MIT-green?style=flat-square" alt="License"></a>
  </p>
  <p align="center">
    <a href="README.md">English</a> Â· <b>ä¸­æ–‡</b>
  </p>
</p>

---

## ä¸€å¥è¯å®‰è£…

```bash
clawhub install mlx-local-inference
```

æˆ–ç›´æ¥å…‹éš†ï¼š

```bash
git clone https://github.com/bendusy/mlx-local-inference.git
```

## ä¸ºä»€ä¹ˆåšè¿™ä¸ª

ä½ çš„ M ç³»åˆ— Mac æœ‰å¼ºå¤§çš„ Neural Engine å’Œç»Ÿä¸€å†…å­˜ï¼Œä½†å¤§å¤šæ•° AI å·¥ä½œæµä»ç„¶æŠŠæ¯ä¸ªè¯·æ±‚å‘åˆ°äº‘ç«¯ã€‚**MLX Local Inference Stack** æŠŠä½ çš„ Mac å˜æˆä¸€å°è‡ªç»™è‡ªè¶³çš„ AI å·¥ä½œç«™ï¼Œä¸“ä¸º**å†…å­˜æ•ˆç‡**è®¾è®¡ï¼Œ**16 GB æœºå™¨ä¹Ÿèƒ½æµç•…è¿è¡Œ**ã€‚

## å†…å­˜å ç”¨æ–¹æ¡ˆ

| æ–¹æ¡ˆ | ç©ºé—²å†…å­˜å ç”¨ | å¸¸é©»æ¨¡å‹ |
|:-----|:------------|:---------|
| **16 GB** | ~3 GB | Embedding (0.6B) + ASR (1.7B) |
| **32 GB** | ~3 GB | åŒä¸Š â€” LLM/VLM æŒ‰éœ€åŠ è½½ |

**æ ¸å¿ƒåŸåˆ™ï¼š** ä¸è°ƒç”¨å°±ä¸åŠ è½½ã€‚æ¨¡å‹é¦–æ¬¡ä½¿ç”¨æ—¶ä»ç¼“å­˜åŠ è½½ï¼Œç©ºé—²åè‡ªåŠ¨å¸è½½ã€‚å¸¸é©»çš„åªæœ‰è½»é‡çº§ API æœåŠ¡æœ¬èº«ã€‚

## èƒ½åŠ›ä¸€è§ˆ

| èƒ½åŠ› | æ¨¡å‹ | å†…å­˜ | åŠ è½½ç­–ç•¥ |
|:-----|:-----|:-----|:---------|
| ğŸ“ **å‘é‡åŒ–** | Qwen3-Embedding-0.6B | ~1 GB | **å¸¸é©»åŠ è½½** |
| ğŸ‘‚ **è¯­éŸ³è¯†åˆ«** | Qwen3-ASR-1.7B | ~1.5 GB | **å¸¸é©»åŠ è½½** |
| ğŸ§  **æ¨ç†/å¯¹è¯** | Qwen3.5-35B-A3B (32GB) / Qwen3-14B (16GB) | 20 GB / 9 GB | **æŒ‰éœ€åŠ è½½** |
| ğŸ‘ï¸ **OCR** | PaddleOCR-VL-1.5 | ~3.3 GB | **æŒ‰éœ€åŠ è½½** |
| ğŸ—£ï¸ **è¯­éŸ³åˆæˆ** | Qwen3-TTS-1.7B | ~2 GB | **æŒ‰éœ€åŠ è½½ï¼ˆé»˜è®¤ä¸å¯ç”¨ï¼‰** |

## è‡ªåŠ¨ä¸‹è½½ç¼ºå¤±æ¨¡å‹

é¦–æ¬¡è°ƒç”¨æ—¶ï¼ŒæœåŠ¡å™¨ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹ï¼š

```
[mlx-server] æœªæ‰¾åˆ°æ¨¡å‹: mlx-community/Qwen3-ASR-1.7B-8bit
[mlx-server] æ­£åœ¨ä¸‹è½½... (1.7 GBï¼Œå¿«é€Ÿç½‘ç»œçº¦ 2 åˆ†é’Ÿ)
[mlx-server] ä¸‹è½½å®Œæˆï¼Œæ­£åœ¨åŠ è½½æ¨¡å‹...
```

ä¹Ÿå¯ä»¥æå‰ä¸€æ¬¡æ€§ä¸‹è½½æ‰€æœ‰é»˜è®¤æ¨¡å‹ï¼š

```bash
python ~/.mlx-server/download_models.py
```

æˆ–å•ç‹¬ä¸‹è½½ï¼š

```bash
huggingface-cli download mlx-community/Qwen3-ASR-1.7B-8bit
huggingface-cli download mlx-community/qwen3-embedding-0.6b-4bit
```

## æ•´ä½“æ¶æ„

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    ä½ çš„æ™ºèƒ½ä½“    â”‚
                        â”‚ (OpenClaw ç­‰)   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ OpenAI å…¼å®¹ API
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â–¼               â–¼               â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  ç«¯å£ 8787  â”‚  â”‚ ç«¯å£ 8788 â”‚  â”‚   CLI      â”‚
          â”‚  å¸¸é©»æœåŠ¡   â”‚  â”‚  å¸¸é©»æœåŠ¡  â”‚  â”‚  æŒ‰éœ€è°ƒç”¨   â”‚
          â”‚            â”‚  â”‚           â”‚  â”‚            â”‚
          â”‚ Â· Embed âœ…  â”‚  â”‚ Â· ASR âœ…  â”‚  â”‚ Â· OCR      â”‚
          â”‚ Â· LLM/VLM  â”‚  â”‚ Â· TTS     â”‚  â”‚            â”‚
          â”‚   (æŒ‰éœ€)    â”‚  â”‚  (æŒ‰éœ€)   â”‚  â”‚            â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

âœ… = å¯åŠ¨æ—¶å¸¸é©» | å…¶ä½™ = é¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½ï¼Œç©ºé—²åè‡ªåŠ¨å¸è½½

## ä½¿ç”¨ç¤ºä¾‹

### ğŸ“ å‘é‡åŒ– â€” æ–‡æœ¬åµŒå…¥ï¼ˆå¸¸é©»ï¼‰

```bash
curl http://localhost:8787/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen3-embedding-0.6b", "input": "ä½ å¥½ä¸–ç•Œ"}'
```

### ğŸ‘‚ è¯­éŸ³è¯†åˆ«ï¼ˆå¸¸é©»ï¼‰

```bash
# ç²¤è¯­ / æ™®é€šè¯ / ä¸­è‹±æ··åˆ
curl http://localhost:8788/v1/audio/transcriptions \
  -F file=@audio.wav \
  -F model=mlx-community/Qwen3-ASR-1.7B-8bit \
  -F language=zh
```

æ”¯æŒæ ¼å¼ï¼š`wav`ã€`mp3`ã€`m4a`ã€`flac`ã€`ogg`ã€`webm`

### ğŸ§  æ¨ç†/å¯¹è¯ â€” LLM / è§†è§‰è¯­è¨€ï¼ˆæŒ‰éœ€ï¼Œmlx-vlmï¼‰

```bash
# çº¯æ–‡æœ¬
curl http://localhost:8787/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen3.5-35b", "messages": [{"role": "user", "content": "ä½ å¥½"}]}'

# å›¾æ–‡æ··åˆï¼ˆè§†è§‰è¯­è¨€ï¼‰
curl http://localhost:8787/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen3.5-35b",
    "messages": [{
      "role": "user",
      "content": [
        {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,..."}},
        {"type": "text", "text": "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"}
      ]
    }]
  }'
```

> **16 GB æç¤ºï¼š** ä½¿ç”¨ `qwen3-14b` æ›¿ä»£ `qwen3.5-35b`ã€‚14B æ¨¡å‹çº¦å  9 GBï¼Œä¸ Embedding + ASR å…±å­˜æ²¡æœ‰é—®é¢˜ã€‚

### ğŸ‘ï¸ OCR â€” å›¾åƒæ–‡å­—è¯†åˆ«ï¼ˆæŒ‰éœ€ï¼‰

```bash
python -m mlx_vlm.generate \
  --model mlx-community/PaddleOCR-VL-1.5-6bit \
  --image document.jpg --prompt "OCR:" --max-tokens 512 --temp 0.0
```

### ğŸ—£ï¸ è¯­éŸ³åˆæˆï¼ˆæŒ‰éœ€ï¼Œé»˜è®¤ä¸åŠ è½½ï¼‰

```bash
curl http://localhost:8788/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{"model": "Qwen3-TTS", "input": "ä½ å¥½ä¸–ç•Œ"}' \
  -o speech.wav
```

TTS é¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½ï¼Œç©ºé—²è¶…æ—¶åè‡ªåŠ¨å¸è½½ï¼ˆé»˜è®¤ 5 åˆ†é’Ÿï¼‰ã€‚

### ğŸ“ è‡ªåŠ¨è½¬å½•æµæ°´çº¿

æŠŠéŸ³é¢‘æ–‡ä»¶ä¸¢è¿› `~/transcribe/`ï¼Œå®ˆæŠ¤è¿›ç¨‹è‡ªåŠ¨å¤„ç†ï¼š

1. Qwen3-ASR è½¬å½• â†’ `æ–‡ä»¶å_raw.md`
2. LLM çº é”™ã€è¡¥æ ‡ç‚¹ â†’ `æ–‡ä»¶å_corrected.md`
3. å½’æ¡£è‡³ `~/transcribe/done/`

## æŒ‰å†…å­˜é€‰æ¨¡å‹

### 16 GB Mac

| ç”¨é€” | æ¨¡å‹ | å†…å­˜ |
|:-----|:-----|:-----|
| å‘é‡åŒ– | `qwen3-embedding-0.6b` | ~1 GB |
| è¯­éŸ³è¯†åˆ« | `Qwen3-ASR-1.7B-8bit` | ~1.5 GB |
| LLMï¼ˆæŒ‰éœ€ï¼‰ | `Qwen3-14B-4bit` | ~9 GB |
| OCRï¼ˆæŒ‰éœ€ï¼‰ | `PaddleOCR-VL-1.5-6bit` | ~3.3 GB |
| TTSï¼ˆå¯é€‰ï¼‰ | `Qwen3-TTS-1.7B-8bit` | ~2 GB |

> âš ï¸ 16 GB æœºå™¨ä¸Šï¼Œé¿å…åŒæ—¶è¿è¡Œ LLM + OCRã€‚è½¬å½•å®ˆæŠ¤è¿›ç¨‹ä¼šè‡ªåŠ¨åœ¨ä¸¤ä¸ªé˜¶æ®µä¹‹é—´å¸è½½æ¨¡å‹ã€‚

### 32 GB Mac

| ç”¨é€” | æ¨¡å‹ | å†…å­˜ |
|:-----|:-----|:-----|
| å‘é‡åŒ– | `qwen3-embedding-0.6b` | ~1 GB |
| è¯­éŸ³è¯†åˆ« | `Qwen3-ASR-1.7B-8bit` | ~1.5 GB |
| LLM/VLMï¼ˆæŒ‰éœ€ï¼‰ | `Qwen3.5-35B-A3B-4bit` | ~20 GB |
| OCRï¼ˆæŒ‰éœ€ï¼‰ | `PaddleOCR-VL-1.5-6bit` | ~3.3 GB |
| TTSï¼ˆå¯é€‰ï¼‰ | `Qwen3-TTS-1.7B-8bit` | ~2 GB |

## æœåŠ¡ç®¡ç†

```bash
# é‡å¯ä¸»æœåŠ¡ï¼ˆEmbedding + æŒ‰éœ€ LLM/VLMï¼‰
launchctl kickstart -k gui/$(id -u)/com.mlx-server

# é‡å¯ ASR æœåŠ¡ï¼ˆASR å¸¸é©» + TTS æŒ‰éœ€ï¼‰
launchctl kickstart -k gui/$(id -u)/com.mlx-audio-server

# é‡å¯è½¬å½•å®ˆæŠ¤è¿›ç¨‹
launchctl kickstart gui/$(id -u)/com.mlx-transcribe-daemon

# æŸ¥çœ‹æ—¥å¿—
tail -f ~/.mlx-server/logs/server.log
tail -f ~/.mlx-server/logs/mlx-audio-server.err.log
```

## å‡çº§æ¨¡å‹

```bash
# 1. ä¸‹è½½æ–°æ¨¡å‹
huggingface-cli download mlx-community/<æ–°æ¨¡å‹å>

# 2. æ›´æ–°é…ç½® (~/.mlx-server/config.yaml)
# 3. é‡å¯æœåŠ¡
launchctl kickstart -k gui/$(id -u)/com.mlx-server
```

## ç¯å¢ƒè¦æ±‚

- Apple Silicon Macï¼ˆM1 / M2 / M3 / M4ï¼‰
- macOS 14+
- Python 3.10+
- **æœ€ä½ 16 GB å†…å­˜**ï¼ˆ32 GB æ¨èï¼Œå¯è¿è¡Œ 35B æ¨¡å‹ï¼‰
- mlx-vlm >= 0.3.12

## ç›®å½•ç»“æ„

```
mlx-local-inference/
â”œâ”€â”€ SKILL.md              # OpenClaw æŠ€èƒ½å®šä¹‰
â”œâ”€â”€ README.md             # English
â”œâ”€â”€ README_CN.md          # ä¸­æ–‡ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ LICENSE
â””â”€â”€ references/           # å„æ¨¡å‹è¯¦ç»†æŠ€æœ¯æ–‡æ¡£
```

## è´¡çŒ®

æ¬¢è¿æ Issue å’Œ PRã€‚

## è®¸å¯è¯

[MIT](LICENSE)
